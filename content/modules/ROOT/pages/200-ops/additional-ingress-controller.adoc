= Adding an additional ingress controller to an ARO cluster
:authors: ["Paul Czarkowski", "Stuart Kirk", "Anton Nesterov", "Connor Wooley"]
:date: 2022-03-19
:tags: ["ARO", "Azure"]

== Prerequisites

* an Azure Red Hat OpenShift cluster
* a DNS zone that you can easily modify

== Get Started

. Create some environment variables. You will need to set the email address.
+
[source,bash,subs="+macros,+attributes",role=execute]
----
# Already set in your .bashrc
# DOMAIN_PARENT
# EMAIL
# AZR_DNS_RESOURCE_GROUP

INGRESS_DOMAIN=custom.$DOMAIN_PARENT
SCRATCH_DIR=/tmp/aro
----
+
. Start a tmux session if you're not already in one.
Rejoin your tmux session after connection loss with `tmux a`.
+
[source,bash,subs="+macros,+attributes",role=execute]
----
tmux
----

== Create Certificates
____
This process uses two terminal sessions.
You will switch between them as you work.
One session runs the Let's Encrypt certificate generation interactive process.
The other session is where you'll updated DNS records for Let's Encrypt to validate.
____

. Create a certificate for the ingress controller
+
[source,bash,subs="+macros,+attributes",role=execute]
----
certbot certonly --manual \
  --preferred-challenges=dns \
  --email $EMAIL \
  --server https://acme-v02.api.letsencrypt.org/directory \
  --agree-tos \
  --manual-public-ip-logging-ok \
  -d "*.$INGRESS_DOMAIN" \
  --config-dir "$SCRATCH_DIR/config" \
  --work-dir "$SCRATCH_DIR/work" \
  --logs-dir "$SCRATCH_DIR/logs"
----
NOTE: Take note of the Domain and TXT value fields as these are required for Let's Encrypt to validate that you own the domain and can therefore issue you the certificates.
+
WARNING: Don't close or interrupt this process, we will finish after the dns challenge with the certbot.
+
. Use your mouse to copy the text record VALUE
+
.Example
----
InY85UGzpDLOiS_xpLp-EXAMPLEzfM47BTAJCx2lN6sA
----
. Open a additional terminal with tmux by pressing kbd:[CTRL+b] then kbd:[c]
. Paste the DNS_Challenge in the following environment variable
+
[source,bash,subs="+macros,+attributes",role=execute]
----
export INGRESS_TXT_RECORD="xxxx"
----

. Add the necessary records to validate ownership of the apps domain
+
[source,bash,subs="+macros,+attributes",role=execute]
----
az network dns record-set txt add-record \
  -g $AZR_DNS_RESOURCE_GROUP \
  -z $DOMAIN_PARENT \
  -n "_acme-challenge.custom" \
  -v $INGRESS_TXT_RECORD
----

. Update the TTL for the records from 1h to 5 minutes to testing purposes
+
[source,bash,subs="+macros,+attributes",role=execute]
----
az network dns record-set txt update \
  -g $AZR_DNS_RESOURCE_GROUP \
  -z $DOMAIN_PARENT \
  -n "_acme-challenge.custom" \
  --set ttl=300
----

. Make sure that you get the TXT record from the Azure domain challenge is registered and propagated properly
+
[source,bash,subs="+macros,+attributes",role=execute]
----
dig +short TXT _acme-challenge.custom.$DOMAIN_PARENT
----

. Return to the first terminal with tmux by pressing kbd:[CTRL+b] then kbd:[n]

. Finish the generation of the ingress certificate PKIs for the ARO cluster by pressing kbd:[Enter]

== Create the ingress controller with the new certificate

. Create a secret for the certificate
+
[source,bash,subs="+macros,+attributes",role=execute]
----
oc create secret tls custom-tls \
  -n openshift-ingress \
  --cert=$SCRATCH_DIR/config/live/$INGRESS_DOMAIN/fullchain.pem \
  --key=$SCRATCH_DIR/config/live/$INGRESS_DOMAIN/privkey.pem
----

. Create an ingress controller
+
[source,yaml,subs="+macros,+attributes",role=execute]
----
cat <<EOF | oc apply -f -
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  name: custom
  namespace: openshift-ingress-operator
spec:
  domain: $INGRESS_DOMAIN
  nodePlacement:
    nodeSelector:
      matchLabels:
        node-role.kubernetes.io/worker: ""
  routeSelector:
    matchLabels:
      type: custom
  defaultCertificate:
    name: custom-tls
  httpEmptyRequestsPolicy: Respond
  httpErrorCodePages:
    name: ""
  replicas: 3
EOF
----
+
NOTE: By default the ingress controller is created with `external` scope.
This means that the corresponding Azure Load Balancer will have a public frontend IP.
If you wish to deploy a privately visible ingress controller add the following lines to the `spec`:
+
spec:    ...
endpointPublishingStrategy:      loadBalancer:        scope: Internal      type: LoadBalancerService    ...
+


. Wait a few moments then get the `EXTERNAL-IP` of the new ingress controller
+
[source,bash,subs="+macros,+attributes",role=execute]
----
oc get -n openshift-ingress svc router-custom
----
+
In case of an Externally (publicly) scoped ingress controller the output should look like:
+
----
NAME            TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)                      AGE
router-custom   LoadBalancer   172.30.90.84   20.120.48.78   80:32160/TCP,443:32511/TCP   49s
----
+
In case of an Internal (private) one:
+
----
NAME            TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)                      AGE
router-custom   LoadBalancer   172.30.55.36     10.0.2.4     80:30475/TCP,443:30249/TCP   10s
----

. Optionally verify in the Azure portal or using CLI that the Load Balancer Service has gotten the new Frontend IP and two Load Balancing Rules - one for port 80 and another one for port 443.
In case of an Internally scoped Ingress Controller the changes are to be observed within the Load Balancer that has the `-internal` suffix.
. Create a wildcard DNS record pointing at the `EXTERNAL-IP`
+
[source,bash,subs="+macros,+attributes",role=execute]
----
$INGRESS_EXTERNAL_IP=xx.xx.xx.xx

az network dns record-set a add-record \
  -g $AZR_DNS_RESOURCE_GROUP \
  -z $DOMAIN_PARENT \
  -n '*.custom' \
  -a $INGRESS_EXTERNAL_IP
----

. Test that the Ingress is working
+
NOTE: For the Internal ingress controller, make sure that the test host has the necessary reachability to the VPC/subnet as well as the DNS resolver.
+
[source,bash,subs="+macros,+attributes",role=execute]
----
curl -s https://test.$INGRESS_DOMAIN | head
----
+
----
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
----

. Create a new project to deploy an application to
+
[source,bash,subs="+macros,+attributes",role=execute]
----
oc new-project demo
----

. Create a new application
+
[source,bash,subs="+macros,+attributes",role=execute]
----
oc new-app --docker-image=docker.io/openshift/hello-openshift
----

. Expose
+
[,yaml]
----
cat << EOF | oc apply -f -
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    app: hello-openshift
    app.kubernetes.io/component: hello-openshift
    app.kubernetes.io/instance: hello-openshift
    type: custom
  name: hello-openshift-tls
spec:
  host: hello.$INGRESS_DOMAIN
  port:
    targetPort: 8080-tcp
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
  to:
    kind: Service
    name: hello-openshift
EOF
----

. Verify it works
+
[source,bash,subs="+macros,+attributes",role=execute]
----
curl https://hello.$INGRESS_DOMAIN
----
+
[source,bash,subs="+macros,+attributes",role=execute]
----
Hello OpenShift!
----

== Congratulations

You've completed adding an additional ingress controller to an ARO cluster

Let's move onto the next lab:
xref:200-ops/acr.adoc[Using Azure Container Registry in Private ARO clusters]
